{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d92f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sem, t\n",
    "from numpy import mean, std\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from user_agents import parse\n",
    "from tensorflow.keras.losses import mse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43f7ce",
   "metadata": {},
   "source": [
    "<b>Feature Engineering - Password Spray</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create features for the detection of password spray attacks. We define the following features:\n",
    "- Shifting time window features. These are applied to each split of the dataset.\n",
    "- Features resulting from discretization of 'createdDateTime', 'status.errorCode', and 'userAgent' features.\n",
    "\n",
    "    Using the following status codes (errorCode) to define failed login attempts:\n",
    "     - 50053 - \"The account is locked because the user tried to sign in too many times with an incorrect user ID or password. The user is blocked due to repeated sign-in attempts.\"\n",
    "        / \"Or, sign-in was blocked because it came from an IP address with malicious activity.\"\n",
    "     - 50055 - \"The password is expired. The user's password is expired, and therefore their login or session was ended.\"\n",
    "     - 50126 - \"Error validating credentials due to invalid username or password. The user didn't enter the right credentials\"\n",
    "'''\n",
    "\n",
    "df_training['createdDateTime'] = pd.to_datetime(df_training['createdDateTime'])\n",
    "df_test['createdDateTime'] = pd.to_datetime(df_test['createdDateTime'])\n",
    "df_threshold['createdDateTime'] = pd.to_datetime(df_threshold['createdDateTime'])\n",
    "df_validation['createdDateTime'] = pd.to_datetime(df_validation['createdDateTime'])\n",
    "\n",
    "\n",
    "#Define the status error codes to consider in the creation of shifting time window features\n",
    "failure_codes = [50053, 50126, 50055]\n",
    "\n",
    "#List of time window sizes to be used\n",
    "time_windows = ['30min', '2D', '60min','1D', '4H', '6H', '8H', '12H'] \n",
    "\n",
    "#######################################################################\n",
    "##################Nominal/Datetime Features Binning####################\n",
    "#######################################################################\n",
    "\n",
    "datasets = [\n",
    "    df_training,\n",
    "    df_test,\n",
    "    df_threshold,\n",
    "    df_validation\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # Discretizing the \"createdDateTime\" column\n",
    "    dataset['Hour'] = dataset['createdDateTime'].dt.hour\n",
    "    dataset['Day'] = dataset['createdDateTime'].dt.dayofweek + 1\n",
    "    \n",
    "    # Extract the 'Browser', 'OS', and 'Mobile' from the 'userAgent' features\n",
    "    dataset['Browser'] = dataset['userAgent'].apply(lambda x: parse(x).browser.family)\n",
    "    dataset['OS'] = dataset['userAgent'].apply(lambda x: parse(x).os.family)\n",
    "    dataset['Mobile'] = dataset['userAgent'].apply(lambda x: 1 if parse(x).is_mobile else 0)\n",
    "    \n",
    "    # Boolean feature stating whether an error code represents failure or success\n",
    "    dataset['failureCode'] = dataset['errorCode'].apply(lambda x: 1 if x in failure_codes else 0)\n",
    "    \n",
    "    # Binning based on each failure code vs success codes\n",
    "    dataset.loc[dataset['errorCode'] == 50055, 'codeExplained'] = 'Password Expired'\n",
    "    dataset.loc[dataset['errorCode'] == 50126, 'codeExplained'] = 'Invalid Username'\n",
    "    dataset.loc[dataset['errorCode'] == 50053, 'codeExplained'] = 'Account locked'\n",
    "    dataset.loc[~(dataset['errorCode'].isin(failure_codes)), 'codeExplained'] = 'Success Code'\n",
    "\n",
    "\n",
    "##################################################################\n",
    "##################Time Window Feature Creation####################\n",
    "##################################################################\n",
    "\n",
    "def track_attempts_per_group(df, groupby_col, time_windows, failure_codes, count_success=True):\n",
    "    \n",
    "    df = df.set_index('createdDateTime')\n",
    "    df['Country_aux'], _ = pd.factorize(df['Country'])\n",
    "    \n",
    "    for time_window in time_windows:\n",
    "        if groupby_col != \"Country\":\n",
    "            # Apply a function that counts the number of failed attempts.\n",
    "            grouped_failed_attempts = df.groupby(groupby_col, observed=True)['errorCode'].rolling(time_window)\n",
    "                                        .apply(lambda x: np.isin(x, failure_codes).sum(), raw=True).reset_index(level=0, drop=True)\n",
    "            df[f'failedAttemptsCountsPer{groupby_col}Last{time_window}'] = grouped_failed_attempts\n",
    "\n",
    "        if count_success:\n",
    "            \n",
    "            # Count the number of successful attempts.\n",
    "            grouped_successful_attempts = df.groupby(groupby_col, observed=True)['errorCode'].rolling(time_window)\n",
    "                                        .apply(lambda x: (~np.isin(x, failure_codes)).sum(), raw=True).reset_index(level=0, drop=True)\n",
    "            df[f'successfulAttemptsCountsPer{groupby_col}Last{time_window}'] = grouped_successful_attempts\n",
    "\n",
    "            # Compute the difference between failed and successful attempts (for each userId)\n",
    "            df[f'{time_window}AttemptsDifferencePer{groupby_col}'] = grouped_successful_attempts - grouped_failed_attempts\n",
    "        \n",
    "        # Count the number of distinct countries with failed attempts\n",
    "        if groupby_col == \"Country\":\n",
    "\n",
    "            # Consider sign-ins where errorCode is in failure_codes\n",
    "            df_failures = df[df['errorCode'].isin(failure_codes)]\n",
    "            # Group by userId and count distinct countries within each rolling window\n",
    "            unique_countries = df_failures.groupby('userId').rolling(time_window)['Country_aux'].apply(pd.Series.nunique).reset_index(level=0, drop=True)\n",
    "\n",
    "            df[f'{time_window}DistinctCountriesForFailedAttempts'] = unique_countries\n",
    "            df[f'{time_window}DistinctCountriesForFailedAttempts'].fillna(0, inplace=True)\n",
    "    df = df.drop(columns=['Country_aux'])        \n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df    \n",
    "\n",
    "def track_failed_attempts_global(df, time_windows, failure_codes):\n",
    "    df = df.set_index('createdDateTime')\n",
    "    for time_window in time_windows:\n",
    "        # Count the number of failed attempts over the rolling window\n",
    "        failed_attempts = df['errorCode'].rolling(time_window).apply(lambda x: np.isin(x, failure_codes).sum(), raw=True)\n",
    "        \n",
    "        # Assign the result to a new column\n",
    "        df[f'failedAttemptsCountsLast{time_window}'] = failed_attempts\n",
    "    df = df.reset_index(level=0)\n",
    "    return df\n",
    "\n",
    "def distinct_users_failed_attempts(df, time_windows, failure_codes):\n",
    "    df['userId_aux'], _ = pd.factorize(df['userId'])\n",
    "    for time_window in time_windows:\n",
    "        \n",
    "        # Create a new feature name based on the selected time window\n",
    "        feature_name = f'{time_window}FailedAttemptsUserCount'\n",
    "        \n",
    "        # group the dataset by the selected time window and count the number of distinct userIds with failure codes\n",
    "        df_count = df[df['errorCode'].isin(failure_codes)]\n",
    "                        .rolling(time_window, on='createdDateTime')['userId_aux'].apply(pd.Series.nunique)\n",
    "     \n",
    "        # Assign the result directly to the original dataframe\n",
    "        df[feature_name] = df_count\n",
    "        \n",
    "        # Replace missing values with 0\n",
    "        df[feature_name].fillna(0, inplace=True)\n",
    "        \n",
    "    df = df.drop(columns=['userId_aux'])\n",
    "    return df\n",
    "\n",
    "def distinct_users_failed_attempts_per_ip(df, time_windows, failure_codes):\n",
    "    df['userId_aux'], _ = pd.factorize(df['userId'])\n",
    "    for time_window in time_windows:\n",
    "        \n",
    "        # Initialize the name of the feature\n",
    "        feature_name = f'{time_window}FailedAttemptsUserCountPerIP'\n",
    "        \n",
    "        # group the dataset by the selected time window and count the number of distinct userIds with failure codes\n",
    "        df_count = df[df['errorCode'].isin(failure_codes)].groupby('ipAddress', observed=True)\n",
    "                    .rolling(time_window, on='createdDateTime')['userId_aux'].apply(pd.Series.nunique).reset_index(level=0, drop=True)\n",
    "\n",
    "        # Convert df_count to DataFrame for easier merging\n",
    "        df_count = df_count.reset_index()\n",
    "        \n",
    "        # Renaming columns to prepare for the merge\n",
    "        df_count.columns = ['createdDateTime', feature_name]\n",
    "\n",
    "        # Assign the result directly to the original dataframe\n",
    "        df = pd.merge(df, df_count, on='createdDateTime', how='left')\n",
    "        \n",
    "        # Replace missing values with 0\n",
    "        df[feature_name].fillna(0, inplace=True)\n",
    "    df = df.drop(columns=['userId_aux'])\n",
    "    return df\n",
    "\n",
    "# List of columns needed to create the shifting time window features\n",
    "required_columns = ['createdDateTime', 'userId', 'errorCode', 'ipAddress', 'appDisplayName', 'Country']\n",
    "\n",
    "df_training_aux = df_training[required_columns].copy()\n",
    "df_test_aux = df_test[required_columns].copy()\n",
    "df_validation_aux = df_validation[required_columns].copy()\n",
    "df_threshold_aux = df_threshold[required_columns].copy()\n",
    "\n",
    "datasets_aux = [\n",
    "    df_training_aux,\n",
    "    df_test_aux,\n",
    "    df_validation_aux,\n",
    "    df_threshold_aux\n",
    "]\n",
    "\n",
    "# Note that \"Country\" is the same as \"location.countryOrRegion\"\n",
    "column_list = ['userId', 'ipAddress', 'appDisplayName', 'Country']\n",
    "\n",
    "# Apply the functions defined to each split of the dataset\n",
    "for dataset_aux in datasets_aux:\n",
    "    for i in column_list:\n",
    "        print(\"Creating time window features based on the column: \", i)\n",
    "        dataset_aux = track_attempts_per_group(dataset_aux, i, time_windows, failure_codes, (i == \"userId\"))\n",
    "\n",
    "    dataset_aux = distinct_users_failed_attempts(track_failed_attempts_global(dataset_aux, time_windows, failure_codes), time_windows, failure_codes)\n",
    "    dataset_aux = distinct_users_failed_attempts_per_ip(dataset_aux, time_windows, failure_codes)\n",
    "    \n",
    "# Merge the content of the auxiliary dataframes back to the original one    \n",
    "df_training = df_training.merge(df_training_aux, on=required_columns, how='left')\n",
    "df_test = df_test.merge(df_test_aux, on=required_columns, how='left')\n",
    "df_validation = df_validation.merge(df_validation_aux, on=required_columns, how='left')\n",
    "df_threshold = df_threshold.merge(df_threshold_aux, on=required_columns, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75571244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Code used for the normalization of numerical features.\n",
    "'''\n",
    "\n",
    "# Lists of: time window features and categorical features.\n",
    "tw_list = [col for col in df_training.columns.tolist() if any(i in col for i in time_windows)]\n",
    "categorical_features = ['appDisplayName','userAgent', 'Country', 'authenticationStepResultDetail', \n",
    "                        'errorCode',\"Browser\", \"OS\", \"codeExplained\", 'Hour', 'Day'] \n",
    "boolean_features = ['Mobile', 'failureCode']\n",
    "\n",
    "# List of engineered features\n",
    "relevant_features = tw_list + categorical_features + boolean_features\n",
    "\n",
    "# Filter each dataset to contain only relevant features for the anomaly detection task\n",
    "df_training_copy = df_training[relevant_features].copy()\n",
    "df_threshold_copy = df_threshold[relevant_features].copy()\n",
    "\n",
    "# For the validation and test data also keep the ground truth labels for tuning and evaluation\n",
    "df_test_copy = df_test[relevant_features + ['ActualAttack']].copy()\n",
    "df_validation_copy = df_validation[relevant_features + ['ActualAttack']].copy()\n",
    "\n",
    "############################################################################################\n",
    "#################### Normalize numerical features in the datasets. #########################\n",
    "############################################################################################\n",
    "\n",
    "# Instantiate a MinMaxScaler object. Fit on the training set\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(df_training_copy[tw_list])\n",
    "\n",
    "# Normalize each numerical feature using MinMax normalization\n",
    "df_training_copy[tw_list] = scaler.transform(df_training_copy[tw_list])\n",
    "df_test_copy[columns_list] = scaler.transform(df_test_copy[columns_list])\n",
    "df_validation_copy[columns_list] = scaler.transform(df_validation_copy[columns_list])\n",
    "df_threshold_copy[columns_list] = scaler.transform(df_threshold_copy[columns_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ee371",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding the categorical features in the training dataset.\n",
    "The unknown categories are encoded the same (only 0 values)\n",
    "'''\n",
    "\n",
    "# Add the \"Unseen\" category to each categorical feature except to \"Hour\" and \"Day\"\n",
    "unseen_handling_features = ['appDisplayName','userAgent', 'Country', 'authenticationStepResultDetail', \n",
    "                            'errorCode', \"Browser\", \"OS\"]\n",
    "\n",
    "for feature in unseen_handling_features:\n",
    "    df_training[feature] = df_training[feature].astype('str').astype('category').cat.add_categories('Unseen')\n",
    "\n",
    "# Add a \"dummy\" row in the training data, which contains only the value \"Unseen\" for all features in \"unseen_handling_features\"\n",
    "dummy_row = pd.DataFrame([['Unseen'] * len(unseen_handling_features)], columns=unseen_handling_features)\n",
    "df_training = pd.concat([df_training, dummy_row], ignore_index=True)\n",
    "\n",
    "# Creating OneHotEncoder instance on the training set\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "enc_fit = enc.fit(df_training[categorical_features])\n",
    "df_training = df_training.iloc[:-1, :]\n",
    "\n",
    "encoded_df_training = enc_fit.transform(df_training_copy[categorical_features])\n",
    "features = enc_fit.get_feature_names_out(input_features=categorical_features)\n",
    "df_encoded_training = pd.DataFrame(encoded_data_training, columns=features)\n",
    "\n",
    "#Function that replaces unseen values in the test/validation/threshold splits with 'Unseen'\n",
    "def handle_unseen_categories(df, encoder_categories):\n",
    "    for feature, seen_categories in zip(unseen_handling_features, encoder_categories[:-1]):  \n",
    "        # We only consider the features in \"unseen_handling_features\"\n",
    "        df[feature] = df[feature].astype(str).where(df[feature].astype(str).isin(seen_categories), 'Unseen')\n",
    "    return df\n",
    "\n",
    "#########################################################\n",
    "############# For each split that is not training #######\n",
    "#########################################################\n",
    "df_threshold_copy = handle_unseen_categories(df_threshold_copy, enc_fit.categories_)\n",
    "encoded_df_threshold = enc_fit.transform(df_threshold_copy[categorical_features])\n",
    "df_encoded_threshold = pd.DataFrame(encoded_df_threshold, columns=features)\n",
    "\n",
    "df_test_copy = handle_unseen_categories(df_test_copy, enc_fit.categories_)\n",
    "encoded_df_test = enc_fit.transform(df_test_copy[categorical_features])\n",
    "df_encoded_test = pd.DataFrame(encoded_df_test, columns=features)\n",
    "\n",
    "df_validation_copy = handle_unseen_categories(df_validation_copy, enc_fit.categories_)\n",
    "encoded_df_validation = enc_fit.transform(df_validation_copy[categorical_features])\n",
    "df_encoded_validation = pd.DataFrame(encoded_df_validation, columns=features)\n",
    "\n",
    "\n",
    "#############################################\n",
    "##### Join with the original dataframe ######\n",
    "#############################################\n",
    "\n",
    "# Remove any dummy columns that represent \"nan\" values\n",
    "columns_to_remove = ['Hour_nan', 'Day_nan', 'codeExplained_nan'] + categorical_features\n",
    "df_training_copy = df_training_copy.join(df_encoded_training)\n",
    "df_threshold_copy = df_threshold_copy.join(df_encoded_threshold)\n",
    "df_validation_copy = df_validation_copy.join(df_encoded_validation)\n",
    "df_test_copy = df_test_copy.join(df_encoded_test)\n",
    "\n",
    "df_training_copy = df_training_copy.drop(columns=columns_to_remove).copy()\n",
    "df_threshold_copy = df_threshold_copy.drop(columns=columns_to_remove).copy()\n",
    "df_validation_copy = df_threshold_copy.drop(columns=columns_to_remove).copy()\n",
    "df_test_copy = df_threshold_copy.drop(columns=columns_to_remove).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750592e4",
   "metadata": {},
   "source": [
    "<b><font size=\"3\">Password Spray: Modeling Phase</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Selection\n",
    "'''\n",
    "\n",
    "# Shifting time-window features only (one size only)\n",
    "feat_30_min_window = [i for i in tw_list if '30min' in i] #Best performance on the IF model\n",
    "feat_60_min_window = [i for i in tw_list if '60min' in i]\n",
    "feat_1D_min_window = [i for i in tw_list if '1D' in i]\n",
    "feat_2D_min_window = [i for i in tw_list if '2D' in i]\n",
    "feat_4H_min_window = [i for i in tw_list if '4H' in i]\n",
    "feat_6H_min_window = [i for i in tw_list if '6H' in i]\n",
    "feat_8H_min_window = [i for i in tw_list if '8H' in i]\n",
    "feat_12H_min_window = [i for i in tw_list if '12H' in i]\n",
    "\n",
    "# Shifting time-window features only (two sizes)\n",
    "feat_12H_30min_window = [i for i in tw_list if '30min' in i or '12H' in i] # Best performance on the IF model\n",
    "feat_8H_30min_window = [i for i in tw_list if '30min' in i or '8H' in i]\n",
    "feat_1D_30min_window = [i for i in tw_list if '30min' in i or '1D' in i]\n",
    "feat_2D_30min_window = [i for i in tw_list if '30min' in i or '2D' in i]\n",
    "\n",
    "# Best performer + Country feature\n",
    "feat_12H_30min_country_window = [i for i in df_training_copy.columns if '30min' in i or '12H' in i or 'Country_' in i]\n",
    "\n",
    "# Features extracted directly from the sign-in logs.\n",
    "extracted_init = [i for i in df_training_copy.columns if 'appDisplayName_' in i or \n",
    "                  'Country_' in i or 'errorCode_' in i or 'authenticationStepResultDetail_' in i or \n",
    "                  'userAgent_' in i or 'Hour_' in i or 'Day_' in i]\n",
    "\n",
    "# Features extracted directly from the sign-in logs, but \"userAgent\" and \"errorCode\" are binned.\n",
    "extracted_bin = [i for i in df_training_copy.columns if 'Browser_' in i or \n",
    "                            'OS_' in i or 'authenticationStepResultDetail_' in i or \n",
    "                            i in ['failureCode', 'Mobile'] or 'appDisplayName_' in i or \n",
    "                            'Country_' in i or 'Hour_' in i or 'Day_' in i]\n",
    "\n",
    "# List of non-correlated features.\n",
    "# Selection criteria: choose as many 30minute TW features as these features do not have a strong \n",
    "# correlation with shifting time window features with larger time windows. \n",
    "# As such, the set would include more features then, if we chose to select TW features \n",
    "# with size of 60 minutes or larger instead of 30 minutes.\n",
    "\n",
    "non_correlated_features = ['30minAttemptsDifferencePeruserId', '1DFailedAttemptsUserCountPerIP', \n",
    "                            '60minDistinctCountriesForFailedAttempts', 'failedAttemptsCountsLast1D',\n",
    "                            'failedAttemptsCountsLast30min', 'failedAttemptsCountsLast12H',\n",
    "                            'failedAttemptsCountsPerappDisplayNameLast30min', 'failedAttemptsCountsPerappDisplayNameLast1D',\n",
    "                            'failedAttemptsCountsPeripAddressLast1D', 'successfulAttemptsCountsPeruserIdLast30min',\n",
    "                            'failedAttemptsCountsPeruserIdLast30min']\n",
    "\n",
    "all_features = [i for i in df_training_copy.columns]\n",
    "\n",
    "features_dictionary = {\n",
    "    \"feat_30_min_window\": feat_30_min_window,\n",
    "    \"feat_60_min_window\": feat_60_min_window,\n",
    "    \"feat_1D_min_window\": feat_1D_min_window,\n",
    "    \"extracted_init\": extracted_init,\n",
    "    \"non_correlated_features\": non_correlated_features,\n",
    "    \"all_features\": all_features,\n",
    "    \"feat_2D_min_window\": feat_2D_min_window,\n",
    "    \"feat_4H_min_window\": feat_4H_min_window,\n",
    "    \"feat_6H_min_window\": feat_6H_min_window,\n",
    "    \"feat_8H_min_window\": feat_8H_min_window,\n",
    "    \"feat_12H_min_window\": feat_12H_min_window,\n",
    "    \"feat_12H_30min_window\": feat_12H_30min_window,\n",
    "    \"feat_8H_30min_window\": feat_8H_30min_window,\n",
    "    \"extracted_bin\": extracted_bin,\n",
    "    \"feat_12H_30min_country_window\": feat_12H_30min_country_window\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ed31e",
   "metadata": {},
   "source": [
    "<b>Modeling Autoencoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a45ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Autoencoder Model initialization.\n",
    "'''\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Function creating the Autoencoder network\n",
    "def build_autoencoder(drop_r, l2_reg, l_rate, input_dim):\n",
    "    \n",
    "    # Other hyperparameters about the network structure of the AE (chosen empirically)\n",
    "    bottleneck_size = 4        # Controls the size of the encoding\n",
    "    num_hidden_layers = 4      # Controls the number of hidden layers\n",
    "    ratio = 0.5                # Controls the number of neurons in each layer\n",
    "    \n",
    "    # Input layer initialization\n",
    "    layer_dims = [input_dim]\n",
    "    input_layer = layers.Input(shape=(input_dim,))\n",
    "    \n",
    "    # Dense layer with sigmoid activation function\n",
    "    x = layers.Dense(input_dim, activation=\"sigmoid\")(input_layer)\n",
    "\n",
    "    for i in range(num_hidden_layers//2):\n",
    "        new_dim = int(layer_dims[-1] * 0.5)\n",
    "        layer_dims.append(new_dim)\n",
    "    \n",
    "    # Encoding layers\n",
    "    encoder = tf.keras.Sequential([\n",
    "      layers.Dropout(drop_r),\n",
    "      layers.Dense(layer_dims[-2], activation='relu', kernel_regularizer=l2_reg),\n",
    "      layers.Dropout(drop_r),\n",
    "      layers.Dense(layer_dims[-1], activation='relu', kernel_regularizer=l2_reg),\n",
    "      layers.Dropout(drop_r),\n",
    "      layers.Dense(bottleneck_size, activation=activation_func, kernel_regularizer=l2_reg)])(x)\n",
    "    \n",
    "    # Decoding layers\n",
    "    decoder = tf.keras.Sequential([\n",
    "          layers.Dense(layer_dims[-1], activation='relu', kernel_regularizer=l2_reg),\n",
    "          layers.Dense(layer_dims[-2], activation='relu', kernel_regularizer=l2_reg),\n",
    "          layers.Dense(input_dim, activation=\"sigmoid\")])(encoder)\n",
    "    \n",
    "    # Create the autoencoder\n",
    "    autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "    opt = Adam(learning_rate=l_rate)\n",
    "    autoencoder.compile(optimizer=opt, loss='mse')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bf37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid space\n",
    "dropouts = [0.3, 0.5]\n",
    "l2_regs = [1e-6, 5e-6, 1e-5, 5e-5]\n",
    "learning_rates = [1e-5, 5e-5, 1e-4, 5e-4]\n",
    "all_configs = list(itertools.product(dropouts, l2_regs, learning_rates))\n",
    "\n",
    "# Set the number of iterations for random search\n",
    "n_iterations = 50\n",
    "\n",
    "# Other hyperparameters chosen empirically\n",
    "epochs_num = 20\n",
    "selected_batch_size = 64\n",
    "\n",
    "# For computing the CI\n",
    "confidence_level = 0.95 \n",
    "degrees_freedom = 49\n",
    "\n",
    "# Iterate through all of the feature sets\n",
    "for set_name, feature_set in features_dictionary.items():  \n",
    "    \n",
    "    X_train = df_training_copy[feature_set].copy()\n",
    "    X_validation = df_validation_copy[feature_set].copy()\n",
    "    y_validation = df_validation_copy['ActualAttack']\n",
    "    X_threshold = df_threshold_copy[feature_set].copy()\n",
    "    \n",
    "    # Size of input space\n",
    "    input_dimension = X_train.shape[1]\n",
    "    \n",
    "    # List containing the results of the experiments for one feature set in this list\n",
    "    all_results = []\n",
    "    \n",
    "    # Select a hyperparameter configuration\n",
    "    for config in all_configs:\n",
    "        \n",
    "        # Lists to store performance metrics\n",
    "        f1_scores, precisions, recalls, fprs = [], [], [], []\n",
    "        \n",
    "        # Take the average over n_iterations for every model configuration\n",
    "        for iteration in range(n_iterations):\n",
    "\n",
    "            dr = config[0]       #dropout\n",
    "            l2_r = l2(config[1]) #l2_regularization\n",
    "            l_r = config[2]      #learning rate\n",
    "\n",
    "            # Build and train the model\n",
    "            model = build_autoencoder(dr, l2_r, l_r, input_dimension)\n",
    "            model.fit(X_train, X_train, shuffle=False, epochs=epochs_num, batch_size=selected_batch_size, verbose=0)\n",
    "\n",
    "            # Compute the reconstruction error of the threshold set\n",
    "            X_threshold_predicted = model.predict(X_threshold)\n",
    "            re_threshold = np.mean(np.power(X_threshold - X_threshold_predicted, 2), axis=1)\n",
    "\n",
    "            # Use the 3 sigma rule to compute the threshold\n",
    "            threshold = np.mean(re_threshold) + 3 * np.std(re_threshold)\n",
    "\n",
    "            # Validation\n",
    "            X_validation_predicted = model.predict(X_validation)\n",
    "            re_validation = np.mean(np.power(X_validation - X_validation_predicted, 2), axis=1)\n",
    "            \n",
    "            # Assign an anomaly label to each sample in the validation set based on the computed threshold value\n",
    "            y_predicted_validation = [1 if re > threshold else 0 for re in re_validation]\n",
    "\n",
    "            # Compute F1, precision, recall and fpr\n",
    "            tn, fp, fn, tp = confusion_matrix(y_validation, y_predicted_validation).ravel()\n",
    "            f1 = f1_score(y_validation, y_predicted_validation)\n",
    "            precision = precision_score(y_validation, y_predicted_validation, zero_division=1)\n",
    "            recall = recall_score(y_validation, y_predicted_validation)\n",
    "            fpr = fp / (tn + fp)\n",
    "\n",
    "            # Add the computed metric to their corresponding list\n",
    "            f1_scores.append(f1)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            fprs.append(fpr)\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}. F1 score: {f1}.\")\n",
    "\n",
    "        # After n_iterations, compute the average and the CI\n",
    "        \n",
    "        # Average for each metric\n",
    "        avg_f1 = mean(f1_scores)\n",
    "        avg_precision = mean(precisions)\n",
    "        avg_recall = mean(recalls)\n",
    "        avg_fpr = mean(fprs)\n",
    "\n",
    "        # Calculate the standard error of the mean\n",
    "        error_f1 = sem(f1_scores)\n",
    "        error_precision = sem(precisions)\n",
    "        error_recall = sem(recalls)\n",
    "        error_fpr = sem(fprs)\n",
    "\n",
    "        # Calculate the confidence intervals\n",
    "        t_ci_f1 = t.interval(confidence_level, degrees_freedom, avg_f1, error_f1)\n",
    "        t_ci_precision = t.interval(confidence_level, degrees_freedom, avg_precision, error_precision)\n",
    "        t_ci_recall = t.interval(confidence_level, degrees_freedom, avg_recall, error_recall)\n",
    "        t_ci_fpr = t.interval(confidence_level, degrees_freedom, avg_fpr, error_fpr)\n",
    "\n",
    "        print(f\"Average F1 Score: {avg_f1}, Confidence Interval t-Dist: {t_ci_f1}.\")\n",
    "        print(f\"Average Precision: {avg_precision}, Confidence Interval t-Dist: {t_ci_precision}.\")\n",
    "        print(f\"Average Recall: {avg_recall}, Confidence Interval t-Dist: {t_ci_recall}.\")\n",
    "        print(f\"Average FPR: {avg_fpr}, Confidence Interval t-Dist: {t_ci_fpr}.\")\n",
    "        \n",
    "        # Create dictionary with the results for each config\n",
    "        config_result = {\n",
    "                'dropout': dr,\n",
    "                'l2_regularization': config[1],\n",
    "                'learning_rate': l_r,\n",
    "                'avg_f1': avg_f1,\n",
    "                'avg_precision': avg_precision,\n",
    "                'avg_recall': avg_recall,\n",
    "                'avg_fpr': avg_fpr,\n",
    "                't_ci_f1': t_ci_f1,\n",
    "                't_ci_precision': t_ci_precision,\n",
    "                't_ci_recall': t_ci_recall,\n",
    "                't_ci_fpr': t_ci_fpr\n",
    "            }\n",
    "\n",
    "        all_results.append(config_result)\n",
    "\n",
    "    all_results = sorted(all_results, key=lambda x: x['avg_f1'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389acfd",
   "metadata": {},
   "source": [
    "<b>Modeling Isolation Forest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid space\n",
    "parameter_grid = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_samples': [64, 128, 256],\n",
    "    'max_features': [0.1, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    'contamination': [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# Set the number of iterations for random search\n",
    "n_iterations = 100\n",
    "  \n",
    "# Iterate through all of the feature sets\n",
    "for set_name, feature_set in features_dictionary.items(): \n",
    "    all_configs = list(ParameterGrid(parameter_grid))\n",
    "    all_results = []\n",
    "\n",
    "    X_train = df_training_copy[feature_set].copy()\n",
    "    X_validation = df_encoded_validation_sim_copy[feature_set].copy()\n",
    "    y_validation = df_encoded_validation_sim_copy['Attack']\n",
    "\n",
    "    # List containing the results of the experiments for one feature set in this list\n",
    "    all_results = []\n",
    "    \n",
    "    for config in all_configs:\n",
    "        f1_scores, precisions, recalls, fpr_scores, auc_scores = [], [], [], [], []\n",
    "    \n",
    "        for iteration in range(n_iterations):\n",
    "            model = IsolationForest(**config, bootstrap=True, random_state=rng, n_jobs=-2)\n",
    "            model.fit(X_train)\n",
    "\n",
    "            # Isolation Forest anomaly labels\n",
    "            y_predicted_validation = model.predict(X_validation)\n",
    "            \n",
    "            # Transform the predictions from -1 to 1 and from 1 to 0\n",
    "            y_predicted_validation = (y_predicted_validation == -1).astype(int)\n",
    "            \n",
    "            # Compute F1, precision, recall and fpr\n",
    "            f1 = f1_score(y_validation, y_predicted_validation)\n",
    "            precision = precision_score(y_validation, y_predicted_validation, zero_division=1)\n",
    "            recall = recall_score(y_validation, y_predicted_validation)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_validation, y_predicted_validation).ravel()\n",
    "            fpr = fp / (tn + fp)\n",
    "            \n",
    "            f1_scores.append(f1)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            fpr_scores.append(fpr)\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}. F1 score: {f1}\")\n",
    "\n",
    "        # After n_iterations, compute the average and the CI\n",
    "        \n",
    "        # Average for each metric\n",
    "        avg_f1 = mean(f1_scores)\n",
    "        avg_precision = mean(precisions)\n",
    "        avg_recall = mean(recalls)\n",
    "        avg_fpr = mean(fprs)\n",
    "\n",
    "        # Calculate the standard error of the mean\n",
    "        error_f1 = sem(f1_scores)\n",
    "        error_precision = sem(precisions)\n",
    "        error_recall = sem(recalls)\n",
    "        error_fpr = sem(fprs)\n",
    "\n",
    "        # Calculate the confidence intervals\n",
    "        t_ci_f1 = t.interval(confidence_level, degrees_freedom, avg_f1, error_f1)\n",
    "        t_ci_precision = t.interval(confidence_level, degrees_freedom, avg_precision, error_precision)\n",
    "        t_ci_recall = t.interval(confidence_level, degrees_freedom, avg_recall, error_recall)\n",
    "        t_ci_fpr = t.interval(confidence_level, degrees_freedom, avg_fpr, error_fpr)\n",
    "\n",
    "        print(f\"Average F1 Score: {avg_f1}, Confidence Interval t-Dist: {t_ci_f1}.\")\n",
    "        print(f\"Average Precision: {avg_precision}, Confidence Interval t-Dist: {t_ci_precision}.\")\n",
    "        print(f\"Average Recall: {avg_recall}, Confidence Interval t-Dist: {t_ci_recall}.\")\n",
    "        print(f\"Average FPR: {avg_fpr}, Confidence Interval t-Dist: {t_ci_fpr}.\")\n",
    "        \n",
    "        # Create dictionary with the results for each config\n",
    "        config_result = {\n",
    "            **config,\n",
    "            'avg_f1': avg_f1,\n",
    "            'avg_precision': avg_precision,\n",
    "            'avg_recall': avg_recall,\n",
    "            'avg_fpr': avg_fpr,\n",
    "            't_ci_f1': t_ci_f1,\n",
    "            't_ci_precision': t_ci_precision,\n",
    "            't_ci_recall': t_ci_recall,\n",
    "            't_ci_fpr': t_ci_fpr\n",
    "        }\n",
    "    \n",
    "        all_results.append(config_result)\n",
    "        \n",
    "    all_results = sorted(all_results, key=lambda x: x['avg_f1'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a23a9",
   "metadata": {},
   "source": [
    "<b><font size=\"3\">Password Spray: Evaluation Phase</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e46be0",
   "metadata": {},
   "source": [
    "<b>Evaluation Autoencoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72466ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameter configuration\n",
    "dr = 0.3\n",
    "l2_r = l2(1e-6)\n",
    "l_r = 1e-5\n",
    "\n",
    "# Best feature set\n",
    "feature_set = all_features\n",
    "\n",
    "X_train = df_training_copy[feature_set].copy()\n",
    "X_threshold = df_threshold_copy[feature_set].copy()\n",
    "X_test = df_test_copy[feature_set].copy()\n",
    "y_test = df_test_copy['ActualAttack']\n",
    "\n",
    "input_dimension = X_train.shape[1]\n",
    "\n",
    "# Build and train the model\n",
    "model = build_autoencoder(dr, l2_r, l_r, input_dimension)\n",
    "history = model.fit(X_train, X_train, shuffle=False, epochs=epochs_num, batch_size=selected_batch_size, verbose=0)\n",
    "\n",
    "# Compute the reconstruction error of the threshold set\n",
    "X_threshold_predicted = model.predict(X_threshold)\n",
    "re_threshold = np.mean(np.power(X_threshold - X_threshold_predicted, 2), axis=1)\n",
    "\n",
    "# Use the 3 sigma rule to compute the threshold\n",
    "threshold = np.mean(re_threshold) + 3 * np.std(re_threshold)\n",
    "\n",
    "# Assign anomaly label for each sample in X_test\n",
    "X_test_predicted = model.predict(X_test)\n",
    "re_test = np.mean(np.power(X_test - X_test_predicted, 2), axis=1)\n",
    "\n",
    "y_test_predicted = [1 if e > threshold else 0 for e in re_test]\n",
    "\n",
    "# Compute F1, precision, recall and fpr on the test dataset\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred, zero_division=1)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "fpr_test = fp_test / (tn_test + fp_test)\n",
    "\n",
    "print(f\"TP: {tp_test}\")\n",
    "print(f\"FP: {fp_test}\")\n",
    "print(f\"TN: {tn_test}\")\n",
    "print(f\"FN: {fn_test}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1-score: {f1_test:.4f}\")\n",
    "print(f\"FPR: {fpr_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c41bfd",
   "metadata": {},
   "source": [
    "<b>Evaluation Isolation Forest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24caa056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best feature set\n",
    "feature_set = feat_12H_30min_country_window\n",
    "\n",
    "# Best Hyperparameter configuration\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_samples': [64],\n",
    "    'max_features': [0.1],\n",
    "    'contamination': [0.2]\n",
    "}\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# One configuration only\n",
    "all_configs = list(ParameterGrid(param_grid))\n",
    "\n",
    "X_train = df_training_copy[feature_set].copy()\n",
    "X_test = df_encoded_test_sim_copy[feature_set].copy()\n",
    "y_test = df_encoded_test_sim_copy['ActualAttack']\n",
    "\n",
    "model = IsolationForest(**all_configs[0], bootstrap=True, random_state=rng, n_jobs=-2)\n",
    "model.fit(X_train)\n",
    "\n",
    "# Isolation Forest anomaly labels\n",
    "y_predicted_test = model.predict(X_test)\n",
    "\n",
    "# Transform the predictions from -1 to 1 and from 1 to 0\n",
    "y_predicted_test = (y_predicted_test == -1).astype(int)\n",
    "\n",
    "f1_test = f1_score(y_test_2, y_predicted_test)\n",
    "precision_test = precision_score(y_test_2, y_predicted_test, zero_division=1)\n",
    "recall_test = recall_score(y_test_2, y_predicted_test)\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test_2, y_predicted_test).ravel()\n",
    "fpr_test = fp_test / (tn_test + fp_test)\n",
    "\n",
    "print(f\"TP: {tp_test}\")\n",
    "print(f\"FP: {fp_test}\")\n",
    "print(f\"TN: {tn_test}\")\n",
    "print(f\"FN: {fn_test}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1-score: {f1_test:.4f}\")\n",
    "print(f\"FPR: {fpr_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idsvenv",
   "language": "python",
   "name": "idsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
